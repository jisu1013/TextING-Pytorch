max_doc_length 58 min_doc_length 1 average 11.61
training_vocab 24747 test_vocab 20904 intersection 20778

<remove_word 결과>
stopword list = ['의', '은', '는', '걍', '과', '도', '를', '으로', '자', '에', '와', '하다', '이', '있', '하', '것', '들', '그', '되', '수', '이',
 '보', '않', '없', '나', '사람', '주', '아니', '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇',
 '위하', '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', '많', '그리고',
 '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', '그러', '속', '하나', '집', '살', '모르', '적', 
'월', '데', '자신', '안', '어떤', '내', '내', '경우', '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른',
 '어떻', '여자', '개', '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓']
min_len : 1
max_len : 78
average_len : 12.708584801706447
word count: 56574

<build_graph>
using 3 window size
using unweighted graph
loading raw data
building graphs for training
0 135001
building graphs for training + validation
0 150001
building graphs for test
150001 198315
max_doc_length 72 min_doc_length 1 average 14.67
training_vocab 50120 test_vocab 29910 intersection 23456
Nan 값 (공백 제거)
133550 / 14838 / 49450

<Dataset>
Naver sentiment movie corpus v1.0
Each file is consisted of three columns: id, document, label
	id: The review id, provieded by Naver
	document: The actual review
	label: The sentiment class of the review. (0: negative, 1: positive)
	Columns are delimited with tabs (i.e., .tsv format; but the file extension is .txt for easy access for novices)
200K reviews in total
	ratings.txt: All 200K reviews
	ratings_test.txt: 50K reviews held out for testing
	ratings_train.txt: 150K reviews for training
All reviews are shorter than 140 characters
Each sentiment class is sampled equally (i.e., random guess yields 50% accuracy)
	100K negative reviews (originally reviews of ratings 1-4)
	100K positive reviews (originally reviews of ratings 9-10)
	Neutral reviews (originally reviews of ratings 5-8) are excluded